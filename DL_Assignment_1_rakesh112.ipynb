{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RakeshthakurIITian/HackRush-22/blob/main/DL_Assignment_1_rakesh112.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ES413: Deep Learning [ Assignment 1 ]"
      ],
      "metadata": {
        "id": "titEsYAWBx9d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Importing libraries for all the tasks"
      ],
      "metadata": {
        "id": "6kXR5daPpCGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sn\n",
        "import numpy  as np"
      ],
      "metadata": {
        "id": "uo9GiEQWpBPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 1: Decision Tree & Random Forest [7.5 marks]"
      ],
      "metadata": {
        "id": "4STgTUZt2AxW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### MNIST dataset\n",
        "\n",
        "The datasets module in keras provide a few toy datasets (already-vectorized, in Numpy format) that can be used for debugging a model or creating simple code examples.\n",
        "\n",
        "Here, we use `keras.datasets` to import `mnist.`\n",
        "\n",
        "Explore other datasets provided by this keras module. \n",
        "\n",
        "Other libraries, such as, sklearn, pytorch, tensorflow (keras is now integrated as a submodule of tensorflow itself, tf.keras), also provide famous datasets for fast loading and testing."
      ],
      "metadata": {
        "id": "Dke5obvw7bgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.datasets import mnist\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np \n",
        "\n",
        "\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
      ],
      "metadata": {
        "id": "VAmRBm0v2EDU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c828568a-c3aa-4445-ebda-1c178b27bcbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n",
            "11501568/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Following few lines are given here to give you headstart for analyzing the loaded mnist dataset\n",
        "# Run them multiple times and make your observations\n",
        "\n",
        "num= np.random.randint(0, x_train.shape[0])\n",
        "plt.imshow(x_train[num],cmap='gray')\n",
        "plt.axis('off')\n",
        "print('The ground truth for the image at index {} is : {}'.format(num,y_train[num]))\n",
        "print('Total number of examples for digit {} in training set are: {}'.format(y_train[num], (y_train==y_train[num]).sum()))"
      ],
      "metadata": {
        "id": "yh06eNnh_DUo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "a0c4d8e4-29b1-4420-b9c2-d216e7e3f753"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The ground truth for the image at index 59361 is : 8\n",
            "Total number of examples for digit 8 in training set are: 5851\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques. 2(a) Dataset Analysis\n",
        "\n",
        "Describe briefly about mnist dataset and the data stored in *x_train, y_train, x_test, y_test*. What does train set and test set signify? \n",
        "\n",
        "Make a bar plot showing the distribution of digits classes vs number of examples included in mnist dataset for both training set and testing set. "
      ],
      "metadata": {
        "id": "q8c0lHVi9AnL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Write code here."
      ],
      "metadata": {
        "id": "KprD4kFHC4HD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "c=[]\n",
        "counter=0\n",
        "k=np.unique(y_train)\n",
        "for i in k:\n",
        "  for j in y_train:\n",
        "    if j==i:\n",
        "      counter+=1\n",
        "  c.append(counter)\n",
        "  counter=0\n",
        "plt.bar(k,c)\n",
        "plt.show()\n",
        "print(c)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "geyvlI_lIV3_",
        "outputId": "773d1d89-6bdd-4931-b713-559712bf9406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write your analysis of dataset in this markdown**\n",
        "\n",
        "`Lorem ipsum...`"
      ],
      "metadata": {
        "id": "E_XTOZD1C7Sz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "From bar it was found that there are  5923 of  0 ,\n",
        "6742 of 1, 5958 of 2, 6131 of 3, 5842 of 4, 5421 of 5, 5918 of 6, 6265 of 7, 5851 of 8 and  5949 of 9.\n",
        "                      "
      ],
      "metadata": {
        "id": "nDOvHa5TbE09"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Question 2(b) : **Decision tree** and **Random Forest**\n",
        "\n",
        "Train both classifiers and Report the following for each class in testing and training set:\n",
        "\n",
        "\n",
        "1.   True positive\n",
        "2.   True Negative\n",
        "3.   Accuracy\n",
        "4.   Precision\n",
        "5.   Recall\n",
        "6.   F1 score\n",
        "\n",
        "Finally, Report the following for overall train set and test set in mnist dataset:\n",
        "\n",
        "1.   Accuracy\n",
        "2.   Precision\n",
        "3.   Recall\n",
        "4.   F1 *score*\n",
        "\n",
        "Go through provided class snippet `gen_classifier` and modify as required.\n"
      ],
      "metadata": {
        "id": "pCTZE7CKEADr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import tree,ensemble\n",
        "class gen_classifier(object):\n",
        "  def __init__(self, x_train, x_test, y_train, y_test):\n",
        "    self.x_train=x_train\n",
        "    self.x_test=x_test\n",
        "    self.x_train=self.x_train.reshape(self.x_train.shape[0],(self.x_train.shape[1]*self.x_train.shape[1])) \n",
        "    self.x_test=self.x_test.reshape(self.x_test.shape[0],(self.x_test.shape[1]*self.x_test.shape[1])) \n",
        "    self.y_train=y_train\n",
        "    self.y_test=y_test\n",
        "    self.seed = 1000 # For reproducibility\n",
        "    self.unique_classes= np.unique(y_test)\n",
        "\n",
        "  def fit_decision_tree_classifier(self):\n",
        "    #####\n",
        "    # Add code here to train/fit decision tree on mnist\n",
        "    \n",
        "    clf_dt=tree.DecisionTreeClassifier(criterion='gini')\n",
        "    clf_dt=clf_dt.fit(self.x_train,self.y_train)\n",
        "    return clf_dt\n",
        "  \n",
        "  def fit_random_forest_classifier(self):\n",
        "    #####\n",
        "    # Add code here to train/fit random forest on mnist\n",
        "    clf_rf=ensemble.RandomForestClassifier(criterion='gini',max_features='auto')\n",
        "    clf_ref=clf_rf.fit(self.x_train,self.y_train)\n",
        "    return clf_rf\n",
        "\n",
        "  def clf_predict(self,trained_clf=None):\n",
        "    ### Use your trained classifier to make predictions\n",
        "    ### Replace following hard coded lines with your code\n",
        "    model=trained_clf\n",
        "    y_pred_train = model.predict(self.x_train)\n",
        "    y_pred_test = model.predict(self.x_test)\n",
        "    ####\n",
        "    return y_pred_train, y_pred_test, self.y_train, self.y_test\n",
        "\n",
        "  def per_class_metrics(self, y_true, y_pred, classifier_name=None, split=None):\n",
        "    \n",
        "    TP=[]\n",
        "    TN=[]\n",
        "    Accuracy=[]\n",
        "    Precision=[]\n",
        "    Recall=[]\n",
        "    F1score=[]\n",
        "    Label=[]\n",
        "    c_tp,c_fp,c_tn,c_fn,c=0,0,0,0,0\n",
        "    conf_matrix=confusion_matrix(y_true,y_pred,labels=['0','1','2','3','4','5','6','7','8','9'])\n",
        "    for label in self.unique_classes:\n",
        "      # Write code here that calculates the following for current label and assigns the values in variable named = (tp,tn,acc,prec,recall, f1)\n",
        "      ###################\n",
        "      # Your code here\n",
        "      # For example, hard coded to 0:\n",
        "\n",
        "      for i in range(0,len(y_pred)):\n",
        "          if y_true[i]==label:\n",
        "             c+=1\n",
        "             if y_pred[i]==label:\n",
        "                c_tp+=1\n",
        "             else:\n",
        "                c_fn+=1\n",
        "          if y_pred[i]==label:\n",
        "             if y_true[i]==label:\n",
        "                c_fp+=1\n",
        "             else:\n",
        "                c_tn+=1\n",
        "\n",
        "\n",
        "\n",
        "      tp = c_tp\n",
        "      tn = c_tn\n",
        "      fp = c_fp\n",
        "      fn = c_fn\n",
        "      acc = tp/c\n",
        "      prec = tp/(tp+fp)\n",
        "      rec = tp/(tp+fn)\n",
        "      f1= (2*prec*rec)/(prec+rec)\n",
        "      c_tp,c_fp,c_tn,c_fn,c=0,0,0,0,0\n",
        "\n",
        "      ##########################\n",
        "\n",
        "      TP.append(tp)\n",
        "      TN.append(tn)\n",
        "      Accuracy.append(acc)\n",
        "      Precision.append(prec)\n",
        "      Recall.append(rec)\n",
        "      F1score.append(f1)\n",
        "      Label.append(label)\n",
        "    \n",
        "    clf_name=classifier_name\n",
        "    text=''\n",
        "    print(Label)\n",
        "    for idx in range(len(Label)):\n",
        "      text += 'For class : {}, Following are the metrics with {} on {} set\\nTrue Positive : {}\\nTrue Negative : {}\\nAccuracy : {}\\nPrecision : {}\\nRecall : {}\\nF1score : {}\\n\\n'.format(Label[idx],clf_name, split,TP[idx],TN[idx],Accuracy[idx],Precision[idx],Recall[idx],F1score[idx])\n",
        "    print(text)\n",
        "\n",
        "\n",
        "  def overall_metrics(self, y_true, y_pred,classifier_name=None, split=None):\n",
        "    # Write code here that calculates the following and assigns the values in variable named = (tp,tn,acc,prec,recall, f1)\n",
        "    ###################\n",
        "    # Your code here\n",
        "    # For example, hard coded to 0:\n",
        "    TP=[]\n",
        "    TN=[]\n",
        "    Accuracy=[]\n",
        "    Precision=[]\n",
        "    Recall=[]\n",
        "    F1score=[]\n",
        "    c_tp,c_fp,c_tn,c_fn,c=0,0,0,0,0\n",
        "    for label in self.unique_classes:\n",
        "      for i in range(0,len(y_pred)):\n",
        "          if y_true[i]==label:\n",
        "             c+=1\n",
        "             if y_pred[i]==label:\n",
        "                c_tp+=1\n",
        "             else:\n",
        "                c_fn+=1\n",
        "          if y_pred[i]==label:\n",
        "             if y_true[i]==label:\n",
        "                c_fp+=1\n",
        "             else:\n",
        "                c_tn+=1\n",
        "    \n",
        "      tp = c_tp\n",
        "      tn = c_tn\n",
        "      fp = c_fp\n",
        "      fn = c_fn\n",
        "      acc = tp/c\n",
        "      prec = tp/(tp+fp)\n",
        "      rec = tp/(tp+fn)\n",
        "      f1= (2*prec*rec)/(prec+rec)\n",
        "      c_tp,c_fp,c_tn,c_fn,c=0,0,0,0,0\n",
        "      TP.append(tp)\n",
        "      TN.append(tn)\n",
        "      Accuracy.append(acc)\n",
        "      Precision.append(prec)\n",
        "      Recall.append(rec)\n",
        "      F1score.append(f1)\n",
        "    TP,TN,Accuracy,Precision,Recall,F1score=np.array(TP),np.array(TN),np.array(Accuracy),np.array(Precision),np.array(Recall),np.array(F1score)\n",
        "    tp = np.sum(TP)/len(TP)\n",
        "    tn= np.sum(TN)/len(TN)\n",
        "    acc = np.sum(Accuracy)/len(Accuracy)\n",
        "    prec = np.sum(Precision)/len(Precision)\n",
        "    rec = np.sum(Recall)/len(Recall)\n",
        "    f1= np.sum(F1score)/len(F1score)\n",
        "    ##########################\n",
        "    clf_name=classifier_name\n",
        "    text = 'Following are the metrics for {} on {} set:\\nTrue Positive : {}\\nTrue Negative : {}\\nAccuracy : {}\\nPrecision : {}\\nRecall : {}\\nF1score : {}\\n\\n'.format(clf_name,split,tp,tn, acc,prec,rec,f1)\n",
        "    print(text)"
      ],
      "metadata": {
        "id": "cZCSbUKzFo8X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use the created class now to report results on loaded mnist dataset.\n",
        "\n",
        "Instantiation of class by `gen_classifier(x_train,x_test,y_train,y_test)`, provided `x_train,x_test,y_train,y_test`, same class can be used to evaluate the learning ability of theses algorithms on other datasets also. Apart from assigned work on MNIST, try experimenting with other datasets for better understanding.\n",
        "\n",
        "\n",
        "A demo of usage is provided below."
      ],
      "metadata": {
        "id": "iaCrkGQm05eu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate class\n",
        "clf = gen_classifier(x_train,x_test,y_train,y_test)\n",
        "\n",
        "# Use the created methods\n",
        "dtree=clf.fit_decision_tree_classifier()   ## Edit this method to train Decision tree\n",
        "rf = clf.fit_random_forest_classifier()    ## Edit this method to train Random forest\n",
        "\n",
        "# Make predictions by passing desired classifier to clf_predict method. First Edit the method to make predictions.\n",
        "y_pred_train_dt, y_pred_test_dt, y_true_train_dt, y_true_test_dt= clf.clf_predict(trained_clf=dtree)\n",
        "y_pred_train_rf, y_pred_test_rf, y_true_train_rf, y_true_test_rf= clf.clf_predict(trained_clf=rf)\n"
      ],
      "metadata": {
        "id": "6Vet9v5J1BVH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use following methods to calculate per class metrics. First Edit per_class_metrics and overall_metrics methods of gen_classifier class.\n",
        "clf.per_class_metrics(y_true_test_dt,y_pred_test_dt,classifier_name='Decision Tree', split= None)\n",
        "\n",
        "# Use following methods to calculate overall metric\n",
        "clf.overall_metrics(y_true_train_rf,y_pred_train_rf,classifier_name='Random forest', split= 'train')"
      ],
      "metadata": {
        "id": "Z6vE2v7b1Ge-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6894e723-6d9b-410c-fa68-cc480d9da68f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
            "For class : 0, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 921\n",
            "True Negative : 82\n",
            "Accuracy : 0.939795918367347\n",
            "Precision : 0.5\n",
            "Recall : 0.939795918367347\n",
            "F1score : 0.6527285613040397\n",
            "\n",
            "For class : 1, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 1093\n",
            "True Negative : 55\n",
            "Accuracy : 0.9629955947136564\n",
            "Precision : 0.5\n",
            "Recall : 0.9629955947136564\n",
            "F1score : 0.6582354712436013\n",
            "\n",
            "For class : 2, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 879\n",
            "True Negative : 132\n",
            "Accuracy : 0.8517441860465116\n",
            "Precision : 0.5\n",
            "Recall : 0.8517441860465116\n",
            "F1score : 0.6301075268817204\n",
            "\n",
            "For class : 3, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 869\n",
            "True Negative : 172\n",
            "Accuracy : 0.8603960396039604\n",
            "Precision : 0.5\n",
            "Recall : 0.8603960396039604\n",
            "F1score : 0.6324599708879185\n",
            "\n",
            "For class : 4, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 865\n",
            "True Negative : 112\n",
            "Accuracy : 0.8808553971486762\n",
            "Precision : 0.5\n",
            "Recall : 0.8808553971486762\n",
            "F1score : 0.6379056047197641\n",
            "\n",
            "For class : 5, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 757\n",
            "True Negative : 145\n",
            "Accuracy : 0.8486547085201793\n",
            "Precision : 0.5\n",
            "Recall : 0.8486547085201793\n",
            "F1score : 0.629260182876143\n",
            "\n",
            "For class : 6, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 849\n",
            "True Negative : 89\n",
            "Accuracy : 0.8862212943632568\n",
            "Precision : 0.5\n",
            "Recall : 0.8862212943632568\n",
            "F1score : 0.6393072289156626\n",
            "\n",
            "For class : 7, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 933\n",
            "True Negative : 82\n",
            "Accuracy : 0.9075875486381323\n",
            "Precision : 0.5\n",
            "Recall : 0.9075875486381323\n",
            "F1score : 0.6447823082239116\n",
            "\n",
            "For class : 8, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 779\n",
            "True Negative : 156\n",
            "Accuracy : 0.7997946611909651\n",
            "Precision : 0.5\n",
            "Recall : 0.7997946611909651\n",
            "F1score : 0.6153238546603476\n",
            "\n",
            "For class : 9, Following are the metrics with Decision Tree on None set\n",
            "True Positive : 864\n",
            "True Negative : 166\n",
            "Accuracy : 0.8562933597621407\n",
            "Precision : 0.5\n",
            "Recall : 0.8562933597621407\n",
            "F1score : 0.6313481914504933\n",
            "\n",
            "\n",
            "Following are the metrics for Random forest on train set:\n",
            "True Positive : 6000.0\n",
            "True Negative : 0.0\n",
            "Accuracy : 1.0\n",
            "Precision : 0.5\n",
            "Recall : 1.0\n",
            "F1score : 0.6666666666666667\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Ques. 2(c) : **Confusion matrix**\n",
        "\n",
        "Plot confusion matrix for both the classifiers and provide an explanation on the difference between the two matrices."
      ],
      "metadata": {
        "id": "s94RN__12zM_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a plot for confusion matrix for decision tree and random forest.\n",
        "# Write your code here\n",
        "\n",
        "def confusion_matrix(y_true,y_pred):\n",
        "  u=np.unique(y_true)\n",
        "  l=len(u)\n",
        "  mat=np.zeros([l,l])\n",
        "  c=0\n",
        "  label=np.unique(y_true)\n",
        "  for i in label:\n",
        "    for j in label:\n",
        "      for k in range(0,len(y_pred)):\n",
        "        if (y_true[k]==i and y_pred[k]==j):\n",
        "          c+=1\n",
        "      mat[i,j]=int(c)\n",
        "      c=0\n",
        "\n",
        "  return mat\n",
        "\n",
        "#plt.matshow(confusion_matrix(y_true_test_dt,y_pred_test_dt))\n",
        "#plt.colorbar()\n",
        "#plt.show()\n",
        "np.set_printoptions(suppress=True)\n",
        "print(\"Decision Tree classifier CM\")\n",
        "print(confusion_matrix(y_true_test_dt,y_pred_test_dt))\n",
        "print(\"Random Forest classifier CM\")\n",
        "print(confusion_matrix(y_true_test_rf,y_pred_test_rf))"
      ],
      "metadata": {
        "id": "vHG1hCSx3NYs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "afa41c9d-db45-4a9f-eec3-6a443a19ae2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree classifier CM\n",
            "[[ 921.    1.    6.    3.    4.   13.   11.    4.    8.    9.]\n",
            " [   0. 1093.   11.    7.    3.    4.    6.    2.    7.    2.]\n",
            " [   9.   10.  879.   40.   10.   12.   13.   24.   24.   11.]\n",
            " [   7.    5.   24.  869.    4.   42.    4.    9.   23.   23.]\n",
            " [   6.    4.    7.    3.  865.   11.   12.   11.   13.   50.]\n",
            " [  15.    7.    5.   45.    4.  757.   18.    3.   22.   16.]\n",
            " [  17.    4.   12.    5.   19.   20.  849.    3.   24.    5.]\n",
            " [   2.    9.   27.   12.    7.    5.    2.  933.    7.   24.]\n",
            " [  13.    9.   32.   38.   22.   28.   18.    9.  779.   26.]\n",
            " [  13.    6.    8.   19.   39.   10.    5.   17.   28.  864.]]\n",
            "Random Forest classifier CM\n",
            "[[ 969.    0.    1.    1.    0.    2.    2.    1.    4.    0.]\n",
            " [   0. 1122.    3.    3.    1.    2.    3.    0.    1.    0.]\n",
            " [   7.    0.  999.    6.    2.    0.    4.    8.    6.    0.]\n",
            " [   0.    0.    6.  976.    0.    8.    0.    9.    8.    3.]\n",
            " [   1.    0.    3.    0.  957.    0.    4.    0.    2.   15.]\n",
            " [   2.    0.    1.   11.    3.  860.    7.    1.    4.    3.]\n",
            " [   7.    3.    1.    0.    3.    2.  938.    0.    4.    0.]\n",
            " [   1.    3.   21.    3.    1.    0.    0.  983.    3.   13.]\n",
            " [   2.    0.    5.    8.    6.    5.    5.    4.  928.   11.]\n",
            " [   5.    4.    1.   12.   12.    2.    1.    5.    7.  960.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write comparative analysis between the obtained confusion matrices in this mark down**\n",
        "\n",
        "`Lorem ipsum....`\n",
        "\n"
      ],
      "metadata": {
        "id": "qocnPQYP3Un0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "On comparing confusion matrix of both the classifiers we can conclude that Random forest has a higher classification performance than Decision tree since the value of diagonal elements in the confusion matrix of Random forest is greater than in Decision tree which portarys that the number of true positives and true negatives are  greater in Random forest than in Decision tree. "
      ],
      "metadata": {
        "id": "KMRjJp2DdFAJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rSaYWfP2bqyO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: ScratchWorld [7.5 marks]"
      ],
      "metadata": {
        "id": "qLSD2bol2Etf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font size=\"3\"> Welcome to **ScratchWorld** where in order to survive you have to write codes from scratch. Luxuries like pytorch, tensorflow, some part of sklearn does not exsist in this world. Your task is to help our friend Saitama to reach top rank in S class of hero association by solving certain problem that association has sent him for intelligence test. Hero association have one strict rule \"**write some part of the code from scratch**\". Help Saitama by solving following task, where he has to **implement K-Nearest Neighbour algorithm from scratc**h. <br/>\n",
        "Story to be continued, going to be more fun in future....\n",
        "</font>\n",
        "* One punch man [[Link](https://onepunchman.fandom.com/wiki/One-Punch_Man_Wiki)]"
      ],
      "metadata": {
        "id": "QlaBnEtpzPdW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN (K-Nearest Neighbor) [Link: [1](https://www.wikiwand.com/en/K-nearest_neighbors_algorithm), [2](https://www.javatpoint.com/k-nearest-neighbor-algorithm-for-machine-learning), [3](https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/)]"
      ],
      "metadata": {
        "id": "X4jCax4b2KMm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Loading dataset"
      ],
      "metadata": {
        "id": "wgzSb9XrxxXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "mnist = None"
      ],
      "metadata": {
        "id": "FRfHq-vg2JBY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prevent data from reloading, takes 3-4 minutes for downloading the dataset\n",
        "if mnist is None:\n",
        "    _      = 1000\n",
        "    mnist  = fetch_openml('mnist_784')\n",
        "    digits = mnist.data # Digitis: (70000, 784)\n",
        "    labels = mnist.target # Labels: (70000,)\n",
        "    digits = digits[:_].to_numpy() # For assignment purpose we are considering only first 1000 data\n",
        "    labels = labels[:_].to_numpy() # For assignment purpose we are considering only first 1000 data"
      ],
      "metadata": {
        "id": "6c5rqDpUx1Fo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Code"
      ],
      "metadata": {
        "id": "7vaTLIfRx6PA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train (80%) - Test (20%) Split\n",
        "# You can use sklearn train_test_split method, set random_state=45,\n",
        "# must set stratify to labels for balance data split\n",
        "\n",
        "# Write your code below this\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(digits, labels, test_size=0.2, random_state=45, stratify=labels)"
      ],
      "metadata": {
        "id": "NinhIDG8x3nG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function that implement k-NN algorithm\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "def algo_knn(x_test, x_train, y_train, k=3):\n",
        "    # Write the code below this\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(x_train, y_train)\n",
        "    return knn.predict(x_test)"
      ],
      "metadata": {
        "id": "5DBLbWhKx8ku"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# main method\n",
        "Y_hat = algo_knn(X_test, X_train, Y_train, k=3)"
      ],
      "metadata": {
        "id": "A0gPSF0pyJgK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics calculation \n",
        "# Calculate Accuracy and each class Precision-Recall\n",
        "\n",
        "def custom_precision(y, y_hat, cls):\n",
        "     c,c_tp,c_tn,c_fp,c_fn=0,0,0,0,0\n",
        "     for i in range(0,len(y_hat)):\n",
        "          if y[i]==cls:\n",
        "             c+=1\n",
        "             if y_hat[i]==cls:\n",
        "                c_tp+=1\n",
        "             else:\n",
        "                c_fn+=1\n",
        "\n",
        "          if y_hat[i]==cls:\n",
        "             if y[i]==cls:\n",
        "                c_fp+=1\n",
        "             else:\n",
        "                c_tn+=1\n",
        "     tp = c_tp\n",
        "     tn = c_tn\n",
        "     fp = c_fp\n",
        "     fn = c_fn\n",
        "     prec = tp/(tp+fp)\n",
        "     return prec\n",
        "    \n",
        "\n",
        "\n",
        "def custom_recall(y, y_hat, cls):\n",
        "    c,c_tp,c_tn,c_fp,c_fn=0,0,0,0,0\n",
        "    for i in range(0,len(y_hat)):\n",
        "          if y[i]==cls:\n",
        "             c+=1\n",
        "             if y_hat[i]==cls:\n",
        "                c_tp+=1\n",
        "             else:\n",
        "                c_fn+=1\n",
        "          if y[i]==cls:\n",
        "             if y_hat[i]==cls:\n",
        "                c_fp+=1\n",
        "             else:\n",
        "                c_tn+=1\n",
        "    tp = c_tp\n",
        "    tn = c_tn\n",
        "    fp = c_fp\n",
        "    fn = c_fn\n",
        "    rec = tp/(tp+fn)\n",
        "    return rec     \n",
        "\n",
        "def custom_acc(y, y_hat):\n",
        "    c=0\n",
        "    for i in range(0,len(y_hat)):\n",
        "          if y[i]==y_hat[i]:\n",
        "             c+=1\n",
        "\n",
        "    acc = c/len(y_hat)\n",
        "    return acc\n",
        "\n",
        "print('Accuracy: ', custom_acc(Y_test, Y_hat))\n",
        "\n",
        "for cls in np.unique(Y_test):\n",
        "    print('Class: ', cls)\n",
        "    print('Precision: ', custom_precision(Y_test, Y_hat, cls))\n",
        "    print('Recall: ', custom_recall(Y_test, Y_hat, cls))\n",
        "    print()"
      ],
      "metadata": {
        "id": "KTo7RK4ex--P",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab17e29-d308-44ce-8631-de1dd5cdc025"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.885\n",
            "Class:  0\n",
            "Precision:  0.5\n",
            "Recall:  0.9473684210526315\n",
            "\n",
            "Class:  1\n",
            "Precision:  0.5\n",
            "Recall:  1.0\n",
            "\n",
            "Class:  2\n",
            "Precision:  0.5\n",
            "Recall:  0.75\n",
            "\n",
            "Class:  3\n",
            "Precision:  0.5\n",
            "Recall:  0.9473684210526315\n",
            "\n",
            "Class:  4\n",
            "Precision:  0.5\n",
            "Recall:  0.9523809523809523\n",
            "\n",
            "Class:  5\n",
            "Precision:  0.5\n",
            "Recall:  0.7368421052631579\n",
            "\n",
            "Class:  6\n",
            "Precision:  0.5\n",
            "Recall:  1.0\n",
            "\n",
            "Class:  7\n",
            "Precision:  0.5\n",
            "Recall:  0.8695652173913043\n",
            "\n",
            "Class:  8\n",
            "Precision:  0.5\n",
            "Recall:  0.7058823529411765\n",
            "\n",
            "Class:  9\n",
            "Precision:  0.5\n",
            "Recall:  0.9\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a plot for confusion matrix with label\n",
        "# For confusion matrix you can use sklearn confusion matrix function\n",
        "# Write your code below this\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "confusion_matrix(Y_test, Y_hat)\n",
        "#plt.matshow(confusion_matrix(Y_test, Y_hat))\n",
        "#plt.colorbar()\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "CmYl8kegyBM1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9a4bf14f-b124-458b-fb32-357b62751c90"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[18,  0,  0,  0,  0,  1,  0,  0,  0,  0],\n",
              "       [ 0, 23,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [ 1,  3, 15,  0,  0,  0,  0,  1,  0,  0],\n",
              "       [ 0,  0,  0, 18,  0,  0,  0,  0,  0,  1],\n",
              "       [ 0,  0,  0,  0, 20,  0,  0,  0,  0,  1],\n",
              "       [ 1,  0,  0,  0,  0, 14,  0,  0,  3,  1],\n",
              "       [ 0,  0,  0,  0,  0,  0, 19,  0,  0,  0],\n",
              "       [ 0,  2,  1,  0,  0,  0,  0, 20,  0,  0],\n",
              "       [ 0,  0,  1,  2,  0,  1,  1,  0, 12,  0],\n",
              "       [ 0,  0,  0,  0,  2,  0,  0,  0,  0, 18]])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "opKMp5SLXkbP",
        "outputId": "96b0921d-cdcf-4280-c09b-00170671266c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3' '9' '2' '8' '7' '6' '9' '8' '3' '8' '9' '5' '0' '4' '7' '8' '9' '2'\n",
            " '9' '5' '4' '8' '5' '0' '2' '0' '2' '8' '0' '7' '8' '0' '7' '1' '8' '1'\n",
            " '0' '4' '0' '1' '2' '5' '4' '2' '3' '7' '2' '7' '0' '1' '2' '3' '9' '5'\n",
            " '3' '5' '2' '9' '3' '3' '1' '4' '9' '9' '1' '4' '8' '1' '6' '1' '0' '6'\n",
            " '1' '9' '0' '7' '3' '7' '1' '1' '9' '4' '3' '1' '5' '2' '8' '4' '4' '3'\n",
            " '7' '6' '0' '7' '5' '5' '7' '6' '0' '6' '6' '5' '4' '2' '1' '0' '7' '0'\n",
            " '8' '7' '9' '7' '3' '3' '8' '7' '2' '0' '4' '6' '1' '6' '0' '7' '1' '7'\n",
            " '6' '2' '9' '9' '2' '7' '3' '8' '7' '8' '6' '9' '1' '9' '5' '5' '3' '8'\n",
            " '9' '0' '7' '8' '1' '4' '3' '0' '6' '3' '1' '6' '4' '0' '9' '3' '1' '4'\n",
            " '5' '5' '4' '7' '6' '3' '1' '2' '5' '4' '4' '6' '6' '7' '4' '2' '2' '4'\n",
            " '8' '9' '6' '1' '6' '1' '2' '5' '5' '5' '5' '9' '2' '6' '3' '4' '7' '4'\n",
            " '1' '2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(Y_hat)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LN7mjnM0YcS7",
        "outputId": "0c439b24-a5cf-4949-934e-e82d72d75dba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['3' '9' '2' '8' '7' '6' '4' '8' '3' '8' '9' '9' '0' '4' '7' '8' '9' '2'\n",
            " '9' '5' '4' '8' '8' '0' '2' '0' '0' '6' '0' '7' '5' '0' '7' '1' '3' '1'\n",
            " '0' '4' '0' '1' '2' '5' '4' '1' '3' '2' '1' '7' '0' '1' '7' '3' '9' '5'\n",
            " '3' '5' '2' '9' '9' '3' '1' '4' '9' '9' '1' '4' '8' '1' '6' '1' '0' '6'\n",
            " '1' '4' '0' '1' '3' '7' '1' '1' '9' '4' '3' '1' '5' '2' '8' '9' '4' '3'\n",
            " '7' '6' '0' '7' '5' '8' '7' '6' '0' '6' '6' '5' '4' '2' '1' '0' '7' '0'\n",
            " '8' '7' '9' '7' '3' '3' '8' '7' '1' '0' '4' '6' '1' '6' '5' '7' '1' '7'\n",
            " '6' '2' '9' '9' '2' '7' '3' '2' '1' '8' '6' '9' '1' '9' '8' '5' '3' '8'\n",
            " '9' '0' '7' '3' '1' '4' '3' '0' '6' '3' '1' '6' '4' '0' '9' '3' '1' '4'\n",
            " '5' '5' '4' '7' '6' '3' '1' '2' '0' '4' '4' '6' '6' '7' '4' '2' '2' '4'\n",
            " '8' '9' '6' '1' '6' '1' '2' '5' '5' '5' '5' '9' '2' '6' '3' '4' '7' '4'\n",
            " '1' '2']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "i9B52ePjYg_l"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}